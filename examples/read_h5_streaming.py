"""Example of how to read HDF5 files generated by the streaming sampler.

The streaming sampler saves results in an HDF5 file with a group-based structure
to accommodate proteins of different lengths.
"""

import h5py
import numpy as np


def read_streaming_results(h5_path: str) -> dict[int, dict[str, np.ndarray]]:
  """Read results from a streaming HDF5 file.

  Args:
      h5_path: Path to the HDF5 file generated by the streaming sampler.

  Returns:
      Dictionary mapping structure indices to their sequences and logits.
      Each structure has:
        - 'sequences': Array of shape (num_samples, num_noise_levels, sequence_length)
        - 'logits': Array of shape (num_samples, num_noise_levels, sequence_length, 21)
        - 'metadata': Dictionary with structure metadata

  Example:
      >>> results = read_streaming_results("output.h5")
      >>> for idx, data in results.items():
      ...     print(f"Structure {idx}:")
      ...     print(f"  Sequences shape: {data['sequences'].shape}")
      ...     print(f"  Logits shape: {data['logits'].shape}")
      ...     print(f"  Metadata: {data['metadata']}")

  """
  results = {}

  with h5py.File(h5_path, "r") as f:
    # Get all structure groups
    structure_groups = sorted(
      [key for key in f if key.startswith("structure_")],
      key=lambda x: int(x.split("_")[1]),
    )

    for group_name in structure_groups:
      group = f[group_name]

      # Extract data
      sequences = group["sequences"][:]
      logits = group["logits"][:]

      # Extract metadata
      metadata = {
        "structure_index": group.attrs["structure_index"],
        "num_samples": group.attrs["num_samples"],
        "num_noise_levels": group.attrs["num_noise_levels"],
        "sequence_length": group.attrs["sequence_length"],
      }

      structure_idx = metadata["structure_index"]
      results[structure_idx] = {
        "sequences": sequences,
        "logits": logits,
        "metadata": metadata,
      }

  return results


def concatenate_all_structures(h5_path: str, max_length: int | None = None) -> dict:
  """Read and concatenate all structures, padding to a common length if needed.

  Args:
      h5_path: Path to the HDF5 file.
      max_length: Maximum sequence length to pad to. If None, uses the maximum
          length found in the file.

  Returns:
      Dictionary with:
        - 'sequences': Padded array of shape (num_structures, num_samples,
            num_noise_levels, max_length)
        - 'logits': Padded array of shape (num_structures, num_samples,
            num_noise_levels, max_length, 21)
        - 'masks': Boolean mask indicating valid positions
        - 'lengths': Original sequence lengths for each structure

  """
  results = read_streaming_results(h5_path)

  if not results:
    msg = "No structures found in HDF5 file"
    raise ValueError(msg)

  # Determine padding length
  lengths = [data["metadata"]["sequence_length"] for data in results.values()]
  if max_length is None:
    max_length = max(lengths)

  # Get dimensions from first structure
  first_data = next(iter(results.values()))
  num_samples = first_data["metadata"]["num_samples"]
  num_noise = first_data["metadata"]["num_noise_levels"]

  # Pre-allocate arrays
  num_structures = len(results)
  padded_sequences = np.zeros(
    (num_structures, num_samples, num_noise, max_length),
    dtype=np.int32,
  )
  padded_logits = np.zeros(
    (num_structures, num_samples, num_noise, max_length, 21),
    dtype=np.float32,
  )
  masks = np.zeros(
    (num_structures, num_samples, num_noise, max_length),
    dtype=bool,
  )

  # Fill arrays
  for idx, (_struct_idx, data) in enumerate(sorted(results.items())):
    seq_len = data["metadata"]["sequence_length"]
    padded_sequences[idx, :, :, :seq_len] = data["sequences"]
    padded_logits[idx, :, :, :seq_len, :] = data["logits"]
    masks[idx, :, :, :seq_len] = True

  return {
    "sequences": padded_sequences,
    "logits": padded_logits,
    "masks": masks,
    "lengths": np.array(lengths),
  }


if __name__ == "__main__":
  # Example usage
  import sys

  if len(sys.argv) < 2:  # noqa: PLR2004
    print("Usage: python read_h5_streaming.py <path_to_h5_file>")  # noqa: T201
    sys.exit(1)

  h5_path = sys.argv[1]

  # Read individual structures
  print(f"\nReading structures from {h5_path}...")  # noqa: T201
  results = read_streaming_results(h5_path)
  print(f"Found {len(results)} structures")  # noqa: T201

  for idx, data in results.items():
    print(f"\nStructure {idx}:")  # noqa: T201
    print(f"  Sequences shape: {data['sequences'].shape}")  # noqa: T201
    print(f"  Logits shape: {data['logits'].shape}")  # noqa: T201
    print(f"  Metadata: {data['metadata']}")  # noqa: T201

  # Concatenate with padding
  print("\nConcatenating all structures with padding...")  # noqa: T201
  concatenated = concatenate_all_structures(h5_path)
  print(f"Padded sequences shape: {concatenated['sequences'].shape}")  # noqa: T201
  print(f"Padded logits shape: {concatenated['logits'].shape}")  # noqa: T201
  print(f"Masks shape: {concatenated['masks'].shape}")  # noqa: T201
  print(f"Original lengths: {concatenated['lengths']}")  # noqa: T201
